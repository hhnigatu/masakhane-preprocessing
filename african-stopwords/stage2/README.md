One of the current directions of the project is in investigating the feasibility of harvesting online texts from multiple domains for curating better (language-specific and domain-relevant) African stopwords. In that respect, we plan to identify stopwords from monolingual data (of multiple domains) in the following: 
### 1. [Gather monolingual data](sourcing.md): 
The first part involves gathering a list of monolingual sources for the focus African languages. In order to ensur
e diverse, multi-domain stopwords, we will focus on getting data from many domains.
### 2. [Using statistical methods to automatically identify candidate stopwords](code.md): 
Research on stopwords identification have employed various statistical metrics, such as term-frequencyinverse-document-frequency (TF-IDF), entropy, information gain and Kullback-Leibler divergence. We plan to use these statistical methods too to automatically identify candidate stopwords.

### 3. [Human evaluation](eval.md): 
As a final step in ensuring the automatically curated stopwords are
actually in line with the language, we will employ a number of human evaluators to review our stopwords. Only the stopwords that pass the evaluation will be published.
### 4. Open-sourcing the stopwords: 
Finally, we will either integrate the African stopwords into