# Sourcing Team
## Workflow
- Each team member goes to a monolingual source for their language.
- Then get the data (best in `.txt`) and upload to this [Google drive](https://drive.google.com/drive/folders/11tO917ezdjATB-Ct94mUYfBXf0aVCcuS?usp=sharing) (there will be a folder for each language. If there isnâ€™t, then you create one). `Folder name: IS0-639-3 of language`. Consult [this](https://github.com/masakhane-io/masakhane-preprocessing/blob/main/african-stopwords/LANGUAGE-TABLE.md) for language name. 
- Filename of the data you upload : `{source of data}_mono.txt`. Add the data source in the filename. For example, if I get some fon monolingual data from MAFAND, I will save it as `mafand_mono.txt` and save inside the `fon` folder.
> It's important to keep note of the data source. We will need it for the paper and maybe other analysis.   
- If there are any issues write in the `#african-stopwords` channel (and cc Chris Emezue).

## Focus domains
- News (incl. health, sports, politics)
- social media (incl. twitter, facebook, etc)
- religion 

> If there are more you feel we should add (or remove) please let me know (@Chris Emezue).

## Possible sources of monolingual data
You can start from here while looking for where to find monolingual data
- WMT
- MAFAND
- AfriBERTA corpus (monolingual data in 10 languages)
- [Lanfrica](https://www.lanfrica.com/records) (using the language filter tag).
> One idea: could look for MT parallel corpus of your language and only take the monolingual data for the language of interest 


### Deadline for Sourcing: 25th April 2022: 
